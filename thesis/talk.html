<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="generator" content="pandoc">
  <title>talk</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="./reveal.js//dist/reset.css">
  <link rel="stylesheet" href="./reveal.js//dist/reveal.css">
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    span.underline{text-decoration: underline;}
    div.column{display: inline-block; vertical-align: top; width: 50%;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
  </style>
  <link rel="stylesheet" href="./reveal.js//dist/theme/black.css" id="theme">
  <link rel="stylesheet" href="css/metropolis.css"/>
</head>
<body>
  <div class="reveal">
    <div class="slides">

<section id="title-slide">
  <h1 class="title"><div class="line-block">Designing Boundary Interactions<br />
for Simple Mobile Robots</div></h1>
  <p class="author"><div class="line-block">Alexandra (Alli) Nilles</div></p>
  <p class="date"><div class="line-block">Thesis Advisor: Dr. Steven M. LaValle<br />
October 21, 2020</div></p>
</section>

<section class="slide level1">

<section id="roadmap" class="level2">
<h2>Roadmap</h2>
<ul>
<li>Modelling simple robots</li>
<li>Dynamics of “bouncing robot” trajectories</li>
<li>Wild bodies</li>
<li>Design for different tasks</li>
<li>Review of contributions</li>
</ul>
<p>reverse order of title:</p>
<ul>
<li class="fragment">how to model boundary interactions, dynamical consequences (limit cycles)
<ul>
<li class="fragment">learning can replace analytic understanding of dynamics if the learning module can find stable gaits / motion patterns</li>
</ul></li>
<li class="fragment">implications for where these robots do well, where they struggle
<ul>
<li class="fragment">“complex, crowded environments”</li>
<li class="fragment">WAFR2020 shows importance of sensor design, even coarse sensing</li>
</ul></li>
</ul>
</section>
<section id="what-is-a-robot" class="level2">
<h2>What Is a Robot?</h2>
<ul>
<li class="fragment">Required: sensing, computation, action</li>
<li class="fragment">Sometimes we also consider communication, power, form</li>
</ul>
</section>
<section id="general-purpose-mobile-robot-design" class="level2">
<h2>“General purpose” mobile robot design</h2>
<ul>
<li class="fragment">Develop or choose hardware (car, differential drive, etc..)</li>
<li class="fragment">Construct or be provided a map</li>
<li class="fragment">Develop state estimation / localization</li>
<li class="fragment">Develop control system to follow given trajectories</li>
<li class="fragment">Plan collision-free paths</li>
<li class="fragment">User interface (choosing goals / waypoints in workspace)</li>
</ul>
<div class="fragment">
<p>Still very hard! But what if for certain tasks, we didn’t have to do all this?</p>
</div>
</section>
<section id="what-makes-a-robot-simple" class="level2">
<h2>What Makes a Robot “Simple”?</h2>
<div class="columns">
<div class="column" style="width:50%;">
<figure>
<img data-src="figs/d4c981a3f18402a8982a97e401efae4465567263.gif" class="center" height="300" alt="An ATLAS robot using a vacuum cleaner. From IHMC [1]." /><figcaption aria-hidden="true">An ATLAS robot using a vacuum cleaner. From IHMC <span class="citation" data-cites="ackerman2016ihmc">[1]</span>.</figcaption>
</figure>
</div><div class="column" style="width:50%;">
<figure>
<img data-src="figs/e7e601a9409fc61639059dbd1d0b8bd1cfa33338.gif" class="center" height="300" alt="From Mike Johnson, YouTube" /><figcaption aria-hidden="true">From Mike Johnson, YouTube<a href="#/fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a></figcaption>
</figure>
</div>
</div>
</section>
<section id="when-do-we-want-a-simple-robot" class="level2">
<h2>When Do We Want a “Simple” Robot?</h2>
<ul>
<li class="fragment">Some environments lead to unavoidable constraints
<ul>
<li class="fragment">Communication can be constrained by size, distance, transmission medium</li>
<li class="fragment">Computation can be constrained by size, security/privacy needs</li>
<li class="fragment">Cost (multiple redundant robots vs. one general purpose robot)</li>
</ul></li>
<li class="fragment">Ease of testing and verification (and eventually, automated design)</li>
<li class="fragment">Proofs of <em>minimal</em> complexity needed to complete a task</li>
<li class="fragment">Robust, emergent behaviors vs. brittle, “optimal” behaviors</li>
</ul>
</section>
<section id="what-is-a-boundary-interaction" class="level2">
<h2>What is a Boundary Interaction?</h2>
<p>Physical collision or virtual “stopping condition”</p>
<div class="columns">
<div class="column" style="width:50%;">
<p><img data-src="figs/0c32f235d6fcf45371eb048b79817b7b536cc2c7.jpg" width="300" alt="iRobot" /><br />
</p>
</div><div class="column" style="width:50%;">
<p><img data-src="figs/60966e405262e2b6b83eaa964f8f6d6ebf809889.jpg" width="300" alt="Husqvarna" /><br />
</p>
</div>
</div>
</section>
<section id="why-do-we-want-to-understand-boundary-interactions" class="level2">
<h2>Why Do We Want to Understand Boundary Interactions?</h2>
<ul>
<li class="fragment">Useful or necessary to navigate in complex and crowded environments</li>
<li class="fragment">Intuitively useful for decreasing uncertainty and creating robust trajectories</li>
<li class="fragment">Newly enabled by developments in robot materials, sensing, other hardware</li>
</ul>
</section>
<section id="recent-interest-in-intentional-collisions" class="level2">
<h2>Recent Interest in Intentional Collisions</h2>
<div class="columns">
<div class="column" style="width:50%;">
<figure>
<img data-src="figs/75f2c3736a24bf840c572882cba0fc08033348c1.gif" class="center" width="600" alt="Z. Lu, Z. Liu, G. Correa, K. Karydis. Motion Planning for Collision-resilient Robots in Unknown Maps with Risk Reward Trade-off. IROS 2020" /><figcaption aria-hidden="true">Z. Lu, Z. Liu, G. Correa, K. Karydis. <strong>Motion Planning for Collision-resilient Robots in Unknown Maps with Risk Reward Trade-off.</strong> IROS 2020</figcaption>
</figure>
</div><div class="column" style="width:50%;">
<figure>
<img data-src="figs/0f11a5802347d702d3b3f63b172f448d2cbac531.gif" class="center" width="300" alt="M. Mote, M. Egerstedt, E. Feron, A. Bylard, M. Pavone, Collision-Inclusive Trajectory Optimization for Free-Flying Spacecraft. Journal of Guidance, Control, and Dynamics 2020." /><figcaption aria-hidden="true">M. Mote, M. Egerstedt, E. Feron, A. Bylard, M. Pavone, <strong>Collision-Inclusive Trajectory Optimization for Free-Flying Spacecraft.</strong> Journal of Guidance, Control, and Dynamics 2020.</figcaption>
</figure>
</div>
</div>
</section>
<section id="developments-at-small-scales" class="level2">
<h2>Developments at Small Scales</h2>
<div class="columns">
<div class="column" style="width:50%;">
<figure>
<img data-src="figs/0cc909dc307c8921844098e0a3d365de28c8eaad.gif" class="center" height="150" alt="Kantsler, et. al. Ciliary contact interactions dominate surface scattering of swimming eukaryotes. PNAS, 2013." /><figcaption aria-hidden="true">Kantsler, et. al. <strong>Ciliary contact interactions dominate surface scattering of swimming eukaryotes.</strong> PNAS, 2013.</figcaption>
</figure>
<figure>
<img data-src="figs/f6d5e6c2711ca3efae79d47a2c43a0abca29f1d6.gif" class="center" height="150" alt="Di Leonardo, et al. “Bacterial ratchet motors.” PNAS, 2010." /><figcaption aria-hidden="true">Di Leonardo, et al. “Bacterial ratchet motors.” PNAS, 2010.</figcaption>
</figure>
</div><div class="column" style="width:50%;">
<figure>
<img data-src="figs/ea7287f966fffafebc53571a7f93eaa712a051fc.png" class="center" height="300" alt="C. Bechinger, et. al. Active particles in complex and crowded environments. Reviews of Modern Physics, 2016." /><figcaption aria-hidden="true">C. Bechinger, et. al. <strong>Active particles in complex and crowded environments.</strong> Reviews of Modern Physics, 2016.</figcaption>
</figure>
</div>
</div>
</section>
<section id="designing-boundary-interactions" class="level2">
<h2><em>Designing</em> Boundary Interactions</h2>
<ul>
<li class="fragment">Choose models to encompass many different physical realizations</li>
<li class="fragment">Choose a few appplications to ground but focus more on characterizing the design space</li>
<li class="fragment">Not always optimizing for the same thing (shortest path, fewest bounces, mechanical design…)</li>
</ul>
</section>
<section id="related-work" class="level2">
<h2>Related Work</h2>
</section>
<section id="manipulation" class="level2">
<h2>Manipulation</h2>
<ul>
<li>Intelligent use of constraints / contact can enable robust robot behaviors</li>
</ul>
</section>
<section id="robophysics" class="level2">
<h2>Robophysics</h2>
<ul>
<li>Jeffrey Aguilar, Tingnan Zhang, Feifei Qian, Mark Kingsbury, Benjamin McInroe, Nicole Mazouchova, Chen Li, Ryan Maladen, Chaohui Gong, Matt Travers, Ross L. Hatton, Howie Choset, Paul B. Umbanhowar, Daniel I. Goldman, “A review on locomotion robophysics: the study of movement at the intersection of robotics, soft matter and dynamical systems.”</li>
</ul>
</section>
<section id="relationship-to-locomotion-and-manipulation" class="level2">
<h2>Relationship to Locomotion and Manipulation</h2>
<div class="columns">
<div class="column" style="width:50%;">
<p><span class="image">manipulation</span></p>
</div><div class="column" style="width:50%;">
<p><img data-src="figs/737a8b874250f7e82493c142171cfff94c4afb8b.gif" /><br />
</p>
</div>
</div>
<div class="fragment">
<ul>
<li class="fragment">“Funnel chaining”</li>
<li class="fragment">Mason, Goldberg, Erdmann, Lozano-Pérez, Liberzon</li>
</ul>
</div>
</section>
<section id="bouncing-robots" class="level2">
<h2>Bouncing Robots</h2>
</section>
<section id="bouncing-robots-1" class="level2">
<h2>Bouncing Robots</h2>
<div class="columns">
<div class="column" style="width:50%;">
<p>Iterating the same boundary interaction can cause cycles and trapping regions:</p>
<figure>
<img data-src="figs/d8d327b9b2e84fff40d13541537ac51ad28cf3fc.gif" class="center" width="300" alt="example inspired by Thiffeault, et. al. Microorganism billiards. Physica D: Nonlinear Phenomena, 2017" /><figcaption aria-hidden="true">example inspired by Thiffeault, et. al. Microorganism billiards. Physica D: Nonlinear Phenomena, 2017</figcaption>
</figure>
</div><div class="column" style="width:50%;">
<p>Big changes from small perturbations:</p>
<p><img data-src="figs/f77fa8852b8c6dc89f35d5410058248b2cd5e3e7.gif" class="center" width="300" /></p>
</div>
</div>
</section>
<section id="minimalist-boundary-interactions" class="level2">
<h2>Minimalist Boundary Interactions</h2>
<figure>
<img data-src="figs/f8a0110cc6378ba38724f227be60ec8f2a792c4e.gif" class="center" height="270" alt="Lewis, J. S., &amp; O’Kane, J. M. Planning for provably reliable navigation using an unreliable, nearly sensorless robot. The International Journal of Robotics Research, 2013." /><figcaption aria-hidden="true">Lewis, J. S., &amp; O’Kane, J. M. Planning for provably reliable navigation using an unreliable, nearly sensorless robot. The International Journal of Robotics Research, 2013.</figcaption>
</figure>
<section id="the-importance-of-being-in-corners" class="level6">
<h6>The Importance of Being in Corners</h6>
</section>
</section>
<section id="minimalist-boundary-interactions-1" class="level2">
<h2>Minimalist Boundary Interactions</h2>
<ul>
<li class="fragment"><strong>Localization</strong> with limited sensing (O’Kane, LaValle, IEEE Transaction on Robotics, 2007)
<ul>
<li class="fragment">Localization using limit cycles (Alam, Bobadilla, Shell 2017)</li>
</ul></li>
<li class="fragment"><strong>Mapping</strong> (LaValle et. al. 2011)</li>
<li class="fragment"><strong>Navigation</strong> (Lewis, O’Kane IJRR 2013)</li>
<li class="fragment"><strong>Coverage</strong> (Lewis, Feshbach, O’Kane, IROS, 2018)</li>
</ul>
</section>
<section id="methodology" class="level2">
<h2>Methodology</h2>
<p>Switch between controllable baseline behaviors to complete tasks</p>
<p>Behaviors I have focused on are:</p>
<p>cycling, funnelling, wildness</p>
<p><img data-src="figs/7965ed421fb4b1ceed324d945a741ae32269e299.png" class="center" width="500" /><br />
</p>
</section>
<section id="modelling-assumptions" class="level2">
<h2>Modelling Assumptions</h2>
<ul>
<li class="fragment">Robot position modelled as a <em>point</em> in a <em>polygonal environment</em> (possibly with polygonal obstacles).</li>
<li class="fragment">Robots move in <em>straight lines</em> until they encounter a boundary.</li>
</ul>
<div class="fragment">
<p><img data-src="figs/af8acf51902c9f47be570cfc2ae77a528886bf5d.png" class="center" width="600" /><br />
</p>
</div>
</section>
<section id="modelling-uncertainty" class="level2">
<h2>Modelling Uncertainty</h2>
<p>Uncertainty is unavoidable… Plan over <strong>nondeterministic</strong> bounce rules!</p>
<p><img data-src="figs/40f5ecfab6c00da8172fd4d12f05bd5c1e483211.png" class="center" width="400" /></p>
</section>
<section id="how-to-implement" class="level2">
<h2>How to Implement?</h2>
<ul>
<li class="fragment">Differential drive with bump sensors and side-facing range sensor (“rotate-to-parallel”)</li>
<li class="fragment">Contact sensor and mechanical alignment of robot body (“rotate-until-free”)</li>
<li class="fragment">Boundaries can be virtual (laser beams, GPS, visible boundaries, etc)</li>
</ul>
<div data-align="center" style="float:left;padding:24px">
<iframe width="300" height="275" src="figs/robot_vid2.m4v" frameborder="0" allowfullscreen>
</iframe>
</div>
<div data-align="center" style="float;padding:24px">
<iframe width="300" height="250" src="figs/rotate.mp4" frameborder="0" allowfullscreen>
</iframe>
</div>
<div data-align="center" style="float:left">
<p><img src="figs/Petronics-logo.png" style="width:200px"></p>
</div>
</section>
<section id="geometry-influences-dynamics" class="level2">
<h2>Geometry Influences Dynamics</h2>
<p>Given geometry, parameterize points on outer boundary and obstacles.</p>
<p>We can explicitly compute transition function <span class="math inline">\(f\)</span> between points on the boundary.</p>
<p><img data-src="figs/c873ccfb387741617f9dc567f3ed60d0613c1ab3.png" class="center" width="350" /><br />
</p>
</section>
<section id="geometry-influences-dynamics-1" class="level2">
<h2>Geometry Influences Dynamics</h2>
<p><span class="math inline">\(f\)</span> is a <em>contraction mapping</em> iff <span class="math inline">\(|\frac{f(x, \theta) - f(y,\theta)}{x-y} | &lt; 1\)</span></p>
<div class="fragment">
<p>For two mutually visible straight-line segments, this quantity (the <em>contraction coefficient</em>) is independent of <span class="math inline">\(x, y\)</span> and depends only on <span class="math inline">\(\theta\)</span> and the internal angle <span class="math inline">\(\phi\)</span> between the segments.</p>
</div>
<div class="fragment">
<p>Can be used to reduce uncertainty!</p>
<p><img data-src="figs/8be00c7652250a704f9fd0601e1d84aea1334322.gif" class="center" width="150" /><br />
</p>
</div>
</section>
<section id="limit-cycles" class="level2">
<h2>Limit Cycles</h2>
<div class="columns">
<div class="column" style="width:50%;">
<p><img data-src="figs/f4204c3f138b388fafc1764ec9b6168997b68b6f.gif" class="center" width="250" /><br />
</p>
</div><div class="column" style="width:50%;">
<p>To write down a transition function for an entire cycle, compose individual transition functions until the composition is a return map.</p>
<p>A cycle is <strong>stable</strong> when this return map is a <em>contraction mapping</em>: two points under the mapping become closer together.</p>
<p><strong>Proposition:</strong> For all start points on the boundary of all polygons, a constant fixed-angle controller exists which will cause the robot’s trajectory to enter a stable limit cycle.</p>
</div>
</div>
</section>
<section id="planning-for-nondeterministic-bouncing-strategies" class="level2">
<h2>Planning for Nondeterministic Bouncing Strategies</h2>
<p><strong>Planning Problem:</strong> Given start and goal sets on the boundary of the polygonal environment, create a sequence of safe nondeterministic actions that takes the robot from any point in the start set to some point in the goal set.</p>
<ol type="1">
<li>Partition boundary using “visibility events”</li>
<li>Create <em>safe edge-to-edge transition graph</em> using boundary segments</li>
<li>Search for paths and cycles (depending on specification)</li>
<li>Translate paths to strategies</li>
</ol>
</section>
<section id="nondeterministic-planning" class="level2">
<h2>Nondeterministic Planning</h2>
<p>We know the exact map of the environment at planning time.</p>
<div class="fragment">
<p><strong>Bounce rule:</strong> action to take at boundary, convex subset <span class="math inline">\(u \subseteq (0, \pi)\)</span>.</p>
</div>
<div class="fragment">
<p>Planner produces sequence of <strong>bounce rules</strong>.</p>
</div>
</section>
<section id="visibility-decomposition" class="level2">
<h2>Visibility Decomposition</h2>
<p>Equivalence relation on points along boundary with respect to what edges of original polygon they can “see”.</p>
<p><img data-src="figs/436706c29055a0a8774296bbedfc9a445496eda3.png" class="center" width="400" /><br />
</p>
</section>
<section id="defining-safe-actions" class="level2">
<h2>Defining Safe Actions</h2>
<p><strong>Safe actions</strong>: Given two edges (<span class="math inline">\(e_{start}\)</span> and <span class="math inline">\(e_{goal}\)</span>) in the environment polygon, an interval of bounce angles is <strong>safe</strong> iff:</p>
<div class="fragment">
<p>any action in the interval,</p>
</div>
<div class="fragment">
<p>executed from any point on <span class="math inline">\(e_{start}\)</span>,</p>
</div>
<div class="fragment">
<p>will cause the robot to transition to some point on <span class="math inline">\(e_{goal}\)</span>.</p>
</div>
</section>
<section id="forming-the-safe-bounce-visibility-graph" class="level2">
<h2>Forming the Safe Bounce Visibility Graph</h2>
<p><strong>Nodes</strong>: Edges of <em>partitioned</em> polygon.</p>
<p><strong>Edges</strong>: Directed. Present if safe action exists between edge <span class="math inline">\(e_i\)</span> and edge <span class="math inline">\(e_j\)</span>. Edge holds data on safe angle interval.</p>
<div class="fragment">
<p>Algorithm 1 of WAFR 2018 paper: polygon with <span class="math inline">\(n\)</span> vertices will produce bounce visibility graph with <span class="math inline">\(O(n^2)\)</span> nodes and <span class="math inline">\(O(n^4)\)</span> edges.</p>
</div>
</section>
<section id="forming-the-safe-bounce-visibility-graph-1" class="level2">
<h2>Forming the Safe Bounce Visibility Graph</h2>
<p><img data-src="figs/ba1ed5fbb37b6b75f602c6378a61ff4d23ed8674.png" class="center" width="750" /></p>
</section>
<section id="examples-of-search-queries" class="level2">
<h2>Examples of Search Queries</h2>
<p>If we want to give our robot a constant control input, can use breadth-first search with constraint intersection.</p>
<p><img data-src="figs/ff0c33e44ad809fcbd81af6def81e48f14f34433.png" class="center" width="700" /><br />
</p>
</section>
<section id="examples-of-search-queries-1" class="level2">
<h2>Examples of Search Queries</h2>
<p>We can search while bounding the maximum distance travelled by the robot by labelling each edge with the maximum distance travelled by any transition represented by that edge.</p>
<div class="fragment">
<p>Can search for only contracting paths, or keep the total state expansion/contraction under a bounded amount.</p>
</div>
<div class="fragment">
<p>Of all paths from A to B (up to bounded length), which allows the most unreliable robot?</p>
</div>
<div class="fragment">
<p>In all cases, along with a plan, we also get a characterization of how much uncertainty the plan can tolerate (design constraints!)</p>
</div>
</section>
<section id="completeness-and-correctness" class="level2">
<h2>Completeness and Correctness</h2>
<p>This is an exact planner, so all found solutions are correct, and it will not return any infeasible plans.</p>
<div class="fragment">
<p>Limitations:</p>
<ul>
<li>Does not take into account knowledge about initial conditions (within start interval)</li>
<li>Does not allow state splitting during the search (robot state is maintained as one contiguous set of points along the environment boundary)</li>
<li>Does not take into account how some state transitions reduce uncertainty</li>
</ul>
</div>
</section>
<section id="wild-bodies" class="level2">
<h2>Wild Bodies</h2>
</section>
<section id="wild-bodies-1" class="level2">
<h2>Wild Bodies</h2>
<p><img data-src="figs/6c38e5537a91e312f2a21cc44a2c07c6decdf8c1.gif" class="center" width="400" alt="Bobadilla, L., Sanchez, O., Czarnowski, J., Gossman, K., &amp; LaValle, S. M. (2012). Controlling wild bodies using linear temporal logic. In Robotics: Science and Systems." /><br />
</p>
</section>
<section id="self-assembly" class="level2">
<h2>Self-Assembly</h2>
<figure>
<img data-src="figs/85c8b4abf920155999e6476fa5129d0253adf705.gif" class="center" height="200" alt="Stanford YouTube Channel" /><figcaption aria-hidden="true">Stanford YouTube Channel<a href="#/fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a></figcaption>
</figure>
</section>
<section id="weaselball-hub-design" class="level2">
<h2>Weaselball Hub Design</h2>
<div class="center-text">
<p><img src="figs/weaselball_design_iterations.png" style="float:left;height:150px"> <img src="figs/weaselball_design4.jpg" style="float:right;height:150px"></p>
</div>
<div class="columns">
<div class="column" style="width:40%;">
<p><img src="figs/weaselball_stacked.jpg" style="float:left;height:200px"></p>
</div><div class="column" style="width:60%;">
<p>Future work would include <strong>controllable detatching</strong> (electro-permanent magnets or shape-memory alloys)</p>
</div>
</div>
</section>
<section id="self-assembly-and-object-clustering" class="level2">
<h2>Self-Assembly and Object Clustering</h2>
<p><img data-src="figs/2e9b9a206496e23328dd982c14ea163be62de47c.gif" class="center" height="200" /><br />
</p>
<figure>
<img data-src="figs/0dbe917a6f78c09f5d653a199bb812a8bee9a2dc.gif" class="center" height="200" alt="Nilles, A., Wasserman, J., Born, A., Horn, C., Born, J., &amp; LaValle, S. M. A Hardware and Software Testbed for Underactuated Self-Assembling Robots. In 2019 International Symposium on Multi-Robot and Multi-Agent Systems, 2019" /><figcaption aria-hidden="true">Nilles, A., Wasserman, J., Born, A., Horn, C., Born, J., &amp; LaValle, S. M. <strong>A Hardware and Software Testbed for Underactuated Self-Assembling Robots.</strong> In 2019 International Symposium on Multi-Robot and Multi-Agent Systems, 2019</figcaption>
</figure>
</section>
<section id="key-research-insights-and-questions" class="level2">
<h2>Key Research Insights and Questions</h2>
<ol type="1">
<li class="fragment">Control of macro states (“pressure”, “temperature”) can enable manipulation and other useful tasks.</li>
<li class="fragment">Robot-robot interactions affect these macro-states.</li>
<li class="fragment">Robot-boundary interactions affect these macro-states.</li>
<li class="fragment">How to tune and design these interactions?</li>
</ol>
<p>Mayya, Siddharth, Gennaro Notomista, Dylan Shell, Seth Hutchinson, and Magnus Egerstedt. “Non-uniform robot densities in vibration driven swarms using phase separation theory.” IROS, 2019.</p>
</section>
<section id="manipulation-wafr-2020" class="level2">
<h2>Manipulation (WAFR 2020)</h2>
<p><img data-src="figs/ae7580bcb2462d00e16b2d15965659e8db9f9d10.png" class="center" width="600" /></p>
</section>
<section id="manipulation-wafr-2020-1" class="level2">
<h2>Manipulation (WAFR 2020)</h2>
<p><img data-src="figs/74250880df0561c87311fd4b276553041dbc16f5.png" class="center" width="600" /></p>
</section>
<section id="interesting-takeaways" class="level2">
<h2>Interesting Takeaways</h2>
<ul>
<li>movement primitives lend themselves well to abstraction</li>
<li>given information history, three types of state estimation:
<ul>
<li>what states could I have started in to create this information history?</li>
<li>what states could I currently be in?</li>
<li>what states could I reach in the future (with a given controller)?</li>
</ul></li>
</ul>
</section>
<section id="interfaces-and-design" class="level2">
<h2>Interfaces and Design</h2>
<p><img data-src="figs/d98c09af6c1b6f9026d32783b6ce8814ab30841c.jpg" class="center" width="600" /></p>
</section>
<section id="interfaces-and-design-1" class="level2">
<h2>Interfaces and Design</h2>
<p><img data-src="figs/b10fb43bb53178ae636b51ced69ec008e81dfdba.gif" class="center" width="600" /></p>
<p>with Dr. Amy LaViers. Choreographers and movement observers have lots of technologies for specifying movement! Published MOCO 2018.</p>
<p><img data-src="figs/151a55f544bbc1aaa2bd2744db42069f1ec099dc.png" class="center" width="130" /></p>
<p><img data-src="figs/f4204c3f138b388fafc1764ec9b6168997b68b6f.gif" class="center" width="200" /></p>
</section>
<section id="grand-challenges-of-robotics-according-to-rodney-brooks" class="level2">
<h2>“Grand Challenges” of Robotics (according to Rodney Brooks)</h2>
<ul>
<li class="fragment">Aging population</li>
<li class="fragment">Urbanization
<ul>
<li class="fragment">Construction</li>
</ul></li>
<li class="fragment">Climate change</li>
</ul>
</section>
<section id="acknowledgements" class="level2">
<h2>Acknowledgements</h2>
<figure>
<img data-src="figs/197b7098f0f2e85fdae2a156d6c8021b0a010443.jpg" alt="Samara (Yingying) Ren" /><figcaption aria-hidden="true">Samara (Yingying) Ren</figcaption>
</figure>
</section>
</section>
<section id="thank-you" class="slide level1 unnumbered">
<h1 class="unnumbered">Thank you!</h1>
<div id="refs" class="references" role="doc-bibliography">
<div id="ref-ackerman2016ihmc">
<p>[1] E. Ackerman, “IHMC’s atlas robot learning to do some chores,” <em>IEEE Spectrum Blog: Piscataway, NJ, USA</em>, 2016.</p>
</div>
</div>
</section>
<section class="footnotes" role="doc-endnotes">
<hr />
<ol>
<li id="fn1" role="doc-endnote"><p>https://www.youtube.com/watch?v=Q06G-bvGOXE<a href="#/fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2" role="doc-endnote"><p><a href="#/fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>
    </div>
  </div>

  <script src="./reveal.js//dist/reveal.js"></script>

  // reveal.js plugins
  <script src="./reveal.js//plugin/notes/notes.js"></script>
  <script src="./reveal.js//plugin/search/search.js"></script>
  <script src="./reveal.js//plugin/zoom/zoom.js"></script>
  <script src="./reveal.js//plugin/math/math.js"></script>

  <script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
        // Push each slide change to the browser history
        history: true,
        // Transition style
        transition: 'none', // none/fade/slide/convex/concave/zoom
        // The "normal" size of the presentation, aspect ratio will be preserved
        // when the presentation is scaled to fit different resolutions. Can be
        // specified using percentage units.
        width: 800,
        height: 450,
        math: {
          mathjax: '/home/alli/src/MathJax/MathJax.js',
          config: 'TeX-AMS_HTML-full',
          tex2jax: {
            inlineMath: [['\\(','\\)']],
            displayMath: [['\\[','\\]']],
            balanceBraces: true,
            processEscapes: false,
            processRefs: true,
            processEnvironments: true,
            preview: 'TeX',
            skipTags: ['script','noscript','style','textarea','pre','code'],
            ignoreClass: 'tex2jax_ignore',
            processClass: 'tex2jax_process'
          },
        },

        // reveal.js plugins
        plugins: [
          RevealMath,
          RevealNotes,
          RevealSearch,
          RevealZoom
        ]
      });
    </script>
    </body>
</html>
